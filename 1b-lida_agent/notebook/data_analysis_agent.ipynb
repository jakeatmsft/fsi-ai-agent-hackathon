{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent for Data Analysis using LIDA\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "In this notebook, we'll create an AI agent capable of performing data analysis tasks using LIDA. The agent will:\n",
    "\n",
    "1. **Generate Analysis**: Summarize and visualize data based on user queries.\n",
    "2. **Visual Analysis**: Analyze generated charts/images to provide detailed insights.\n",
    "\n",
    "We'll leverage various tools and services, including Azure OpenAI, LIDA, and other Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Setup and Installation](#Setup-and-Installation)\n",
    "2. [Importing Libraries](#Importing-Libraries)\n",
    "3. [Environment Configuration](#Environment-Configuration)\n",
    "4. [Helper Functions](#Helper-Functions)\n",
    "    - [a. Fetch Current Date and Time](#a.-Fetch-Current-Date-and-Time)\n",
    "    - [b. Generate Analysis](#b.-Generate-Analysis)\n",
    "    - [c. Visual Analysis](#c.-Visual-Analysis)\n",
    "5. [AI Agent Setup](#AI-Agent-Setup)\n",
    "    - [a. Define the AI Agent Tool](#a.-Define-the-AI-Agent-Tool)\n",
    "    - [b. Response Formatting Function](#b.-Response-Formatting-Function)\n",
    "6. [Using the AI Agent](#Using-the-AI-Agent)\n",
    "7. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **1. Setup and Installation**\n",
    "\n",
    "First, we'll install all the necessary Python packages required for our AI agent. Ensure you have the latest versions of `pip` and `conda` (if using)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb107478",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install python-dotenv openai azure-identity azure-ai-projects azure-monitor-opentelemetry lida llm llmx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Some packages like `lida`, `llm`, `llmx`, and `lida_tool` might be custom or proprietary. Ensure they are available in your environment or install them from the appropriate sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **2. Importing Libraries**\n",
    "\n",
    "Import all the necessary libraries and modules. This includes standard Python libraries as well as specialized modules for AI and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from lida import Manager, TextGenerationConfig\n",
    "from llmx import llm, TextGenerationConfig\n",
    "import os\n",
    "from typing import Set, Callable, Dict, Any, List, Optional\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Azure and telemetry imports\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AsyncFunctionTool, \n",
    "    RequiredFunctionToolCall, \n",
    "    SubmitToolOutputsAction, \n",
    "    ToolOutput, \n",
    "    AsyncToolSet,\n",
    "    CodeInterpreterTool,\n",
    "    BingGroundingTool\n",
    ")\n",
    "from azure.ai.projects.telemetry.agents import AIAgentsInstrumentor\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **3. Environment Configuration**\n",
    "\n",
    "Set up environment variables using a `.env` file. This file should contain sensitive information like API keys and connection strings.\n",
    "\n",
    "1. **Create a `.env` File**: Ensure you have a `deploy.env` file in your working directory with the following variables:\n",
    "\n",
    "    ```\n",
    "    AZURE_OPENAI_BASE=your_azure_openai_base_endpoint\n",
    "    AZURE_OPENAI_API_KEY=your_azure_openai_api_key\n",
    "    PROJECT_CONNECTION_STRING=your_project_connection_string\n",
    "    ```\n",
    "\n",
    "2. **Load Environment Variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from deploy.env\n",
    "load_dotenv('deploy.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **4. Helper Functions**\n",
    "\n",
    "Define helper functions that will be used by the AI agent for data analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **a. Fetch Current Date and Time**\n",
    "\n",
    "Gets the current date and time, formatted as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_current_datetime(format: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Get the current time as a JSON string, optionally formatted.\n",
    "\n",
    "    :param format (Optional[str]): The format in which to return the current time. Defaults to None.\n",
    "    :return: The current time in JSON format.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    # Use the provided format if available, else use a default format\n",
    "    if format:\n",
    "        time_format = format\n",
    "    else:\n",
    "        time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    time_json = json.dumps({\"current_time\": current_time.strftime(time_format)})\n",
    "    return time_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **b. Generate Analysis**\n",
    "\n",
    "Generates a summary and visual charts based on the provided question and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_analysis(question: str,model_deployment:str, data_input: str, output_folder:str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a summary and visualize the data based on the question.\n",
    "\n",
    "    :param question (str): The analysis question.\n",
    "    :param data_input (str): The data to analyze.\n",
    "    :return: Path to the saved chart image or an error message.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # Initialize LLM with Azure OpenAI\n",
    "    text_gen = llm(\n",
    "        provider=\"openai\",\n",
    "        api_type=\"azure\",\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_BASE\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "        api_version=\"2023-07-01-preview\",\n",
    "    )\n",
    "    lida = Manager(text_gen=text_gen)\n",
    "\n",
    "    # Configure text generation\n",
    "    textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=model_deployment, use_cache=False)\n",
    "\n",
    "    # Summarize the input data\n",
    "    summary = lida.summarize(data_input, summary_method=\"default\", textgen_config=textgen_config)  \n",
    "\n",
    "    # Visualize the summary based on the question\n",
    "    charts = lida.visualize(summary=summary, goal=question, textgen_config=textgen_config)  \n",
    "\n",
    "    if len(charts) > 0:\n",
    "        chart = charts[0]\n",
    "        code = chart.code\n",
    "\n",
    "        # Create a timestamp for saving files\n",
    "        run_timestamp = str(int(time.time()))\n",
    "        \n",
    "        #create output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Save summary to a Python file\n",
    "        #with open(f'{output_folder}/summary_{run_timestamp}.py', 'w') as f:\n",
    "        #    f.write(str(summary))\n",
    "        \n",
    "        # Save generated code to a Python file\n",
    "        with open(f'{output_folder}/code_{run_timestamp}.py', 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        # Save the chart image\n",
    "        chart.savefig(f'{output_folder}/chart_{run_timestamp}.png')\n",
    "        return f'{output_folder}/chart_{run_timestamp}.png'\n",
    "    else:\n",
    "        field_list = str(summary['field_names'])\n",
    "        return f\"Unable to visualize question, please try again with these fields: {field_list}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **c. Visual Analysis**\n",
    "\n",
    "Analyzes the generated chart image to provide detailed insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def visual_analysis(question: str, img_path: str, deployment_model:str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze the chart image and provide detailed insights.\n",
    "\n",
    "    :param question (str): The analysis question.\n",
    "    :param img_path (str): Path to the chart image.\n",
    "    :return: Detailed analysis in JSON format.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(  \n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_BASE\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "        api_version=\"2024-05-01-preview\",  \n",
    "    )  \n",
    "\n",
    "    # Read and encode the image\n",
    "    with open(img_path, 'rb') as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('ascii')\n",
    "\n",
    "    # Define the chat prompt\n",
    "    chat_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Please analyze the image and provide a detailed analysis of the chart for this question: {question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ] \n",
    "    \n",
    "    # Include speech result if speech is enabled  \n",
    "    messages = chat_prompt  \n",
    "        \n",
    "    # Generate the completion  \n",
    "    completion = client.chat.completions.create(  \n",
    "        model=deployment_model,\n",
    "        messages=messages,\n",
    "        max_tokens=800,  \n",
    "        temperature=0,  \n",
    "        top_p=0.95,  \n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0,\n",
    "        stop=None,  \n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return completion.to_json()  \n",
    "        \n",
    "\n",
    "# Statically defined user functions for fast reference with send_email as async but the rest as sync\n",
    "user_async_function_tools: Set[Callable[..., Any]] = {\n",
    "    generate_analysis,\n",
    "    visual_analysis\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **5. AI Agent Setup**\n",
    "\n",
    "Configure and initialize the AI agent using Azure services and LIDA tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user asynchronous function tools\n",
    "user_async_function_tools: Set[Callable[..., Any]] = {\n",
    "    generate_analysis,\n",
    "    visual_analysis\n",
    "}\n",
    "\n",
    "# Initialize tracer for telemetry\n",
    "tracer = trace.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **a. Define the AI Agent Tool**\n",
    "\n",
    "Create a tool that the AI agent will use to perform data analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analysis_agent(question: str, data_input: str, output_folder:str, model_deployment: str) -> str:\n",
    "    \"\"\"\n",
    "    Main function to handle AI agent operations.\n",
    "\n",
    "    :param question (str): The analysis question.\n",
    "    :param data_input (str): The data input for analysis.\n",
    "    :param model_deployment (str): The model deployment configuration.\n",
    "    :return: AI agent's response.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    async with DefaultAzureCredential() as creds:\n",
    "        async with AIProjectClient.from_connection_string(\n",
    "            credential=creds, conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    "        ) as project_client:\n",
    "            \n",
    "            # Configure Azure Monitor for telemetry\n",
    "            application_insights_connection_string = await project_client.telemetry.get_connection_string()\n",
    "            configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "            \n",
    "            # Initialize assistant functions\n",
    "            functions = AsyncFunctionTool(functions=user_async_function_tools)\n",
    "            code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "            # Setup toolset\n",
    "            toolset = AsyncToolSet()\n",
    "            toolset.add(functions)\n",
    "            # Uncomment the next line if you want to add the code interpreter\n",
    "            # toolset.add(code_interpreter)\n",
    "\n",
    "            agent_name = \"data-analysis-assistant2\"\n",
    "\n",
    "            # Check if the agent already exists\n",
    "            agents = await project_client.agents.list_agents()\n",
    "            agent = next((a for a in agents.data if a.name == agent_name), None)\n",
    "\n",
    "            if agent is None:\n",
    "                # Create a new agent if not found\n",
    "                agent = await project_client.agents.create_agent(\n",
    "                    model=model_deployment,\n",
    "                    name=agent_name,\n",
    "                    instructions=(\n",
    "                        'You are a data analyst with access to a tool called generate_analysis '\n",
    "                        'which can perform analysis and save results for you. Use the data_input provided. '\n",
    "                        'Use the generate_analysis tool to answer the question, then use the visual_analysis '\n",
    "                        'to process the image. The answer should be no greater than 1000 characters in length.'\n",
    "                    ),\n",
    "                    tools=functions.definitions #+ code_interpreter.definitions\n",
    "                )\n",
    "                print(f\"Created agent, agent ID: {agent.id}\")\n",
    "            else:\n",
    "                print(f\"Found existing agent: {agent.id}\")\n",
    "\n",
    "            # Create a thread for communication\n",
    "            thread = await project_client.agents.create_thread()\n",
    "            print(f\"Created thread, ID: {thread.id}\")\n",
    "            \n",
    "            # Send a message to the agent\n",
    "            message = await project_client.agents.create_message(\n",
    "                thread_id=thread.id, \n",
    "                role=\"user\", \n",
    "                content=f\"Current date is {datetime.datetime.now().strftime('%Y-%m-%d')}.model_deployment:{model_deployment}, {question},output_folder:{output_folder}, data_input:{data_input}\"\n",
    "            )\n",
    "            print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "            # Process the agent run with the provided tools\n",
    "            run = await project_client.agents.create_and_process_run(\n",
    "                thread_id=thread.id, \n",
    "                assistant_id=agent.id, \n",
    "                toolset=toolset\n",
    "            )\n",
    "            print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "            if run.status == \"failed\":\n",
    "                print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "            print(f\"Run completed with status: {run.status}\")\n",
    "\n",
    "            # Fetch and log all messages from the thread\n",
    "            messages = await project_client.agents.list_messages(thread_id=thread.id)\n",
    "            print(f\"Messages: {messages}\")\n",
    "\n",
    "            # Save any generated files (e.g., images)\n",
    "            for file_path_annotation in messages.file_path_annotations:\n",
    "                print(f\"File Paths:\")\n",
    "                print(f\"Type: {file_path_annotation.type}\")\n",
    "                print(f\"Text: {file_path_annotation.text}\")\n",
    "                print(f\"File ID: {file_path_annotation.file_path.file_id}\")\n",
    "                print(f\"Start Index: {file_path_annotation.start_index}\")\n",
    "                print(f\"End Index: {file_path_annotation.end_index}\")\n",
    "                file_name = Path(file_path_annotation.text).name\n",
    "                await project_client.agents.save_file(\n",
    "                    file_id=file_path_annotation.file_path.file_id, \n",
    "                    file_name=file_name\n",
    "                )\n",
    "                print(f\"Saved image file to: {Path.cwd() / file_name}\")\n",
    "\n",
    "            # Get the last message from the conversation\n",
    "            last_message = messages.text_messages[0].text\n",
    "            response = last_message\n",
    "            return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **6. Using the AI Agent**\n",
    "\n",
    "With the AI agent set up, you can now interact with it by providing questions and data inputs for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_cFo6AFlbNMKuTmSPPwlK9Qyk\n",
      "Created thread, ID: thread_5Bhhc9YsOMhpejhGnNSYmmah\n",
      "Created message, ID: msg_YRlCNHlm1trMDvzKPVx3x0wT\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "Run completed with status: RunStatus.COMPLETED\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_p4ZomPab4gZJyVPFIWnOCXYx', 'object': 'thread.message', 'created_at': 1741292838, 'assistant_id': 'asst_cFo6AFlbNMKuTmSPPwlK9Qyk', 'thread_id': 'thread_5Bhhc9YsOMhpejhGnNSYmmah', 'run_id': 'run_cvXiGHc0nYvXNid2v2Pzwh1M', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': 'The analysis of the MPG data reveals the following key trends:\\n\\n1. **Positive Correlation**: There is a strong positive correlation between City and Highway MPG, indicating that vehicles efficient in city driving are generally efficient on highways as well.\\n\\n2. **Car Type Distribution**:\\n   - **Sedans** show a wide range of MPG values, indicating variability in fuel efficiency.\\n   - **SUVs** tend to have lower MPG, clustering in the lower to mid-range.\\n   - **Sports Cars** display a wide range, similar to sedans.\\n   - **Wagons** and **Minivans** mainly cluster in the mid-range of MPG.\\n\\n3. **High Efficiency Outliers**: Some highly efficient vehicles are outliers, particularly among sedans.\\n\\n4. **Trend Line**: Confirms the positive correlation, with a majority of data points aligning predictably around it.\\n\\n5. **Efficiency Range**: City MPG ranges from ~10-60, and Highway MPG from ~10-70.\\n\\nOverall, sedans and sports cars have the most variability in fuel efficiency, while SUVs generally have lower MPG values.', 'annotations': []}}], 'attachments': [], 'metadata': {}}, {'id': 'msg_YRlCNHlm1trMDvzKPVx3x0wT', 'object': 'thread.message', 'created_at': 1741292815, 'assistant_id': None, 'thread_id': 'thread_5Bhhc9YsOMhpejhGnNSYmmah', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Current date is 2025-03-06.model_deployment:gpt-4o, What are the key trends regarding mpg for sales data set MPG range 0-100?,output_folder:output, data_input:https://raw.githubusercontent.com/uwdata/draco/master/data/cars.csv', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_p4ZomPab4gZJyVPFIWnOCXYx', 'last_id': 'msg_YRlCNHlm1trMDvzKPVx3x0wT', 'has_more': False}\n",
      "AI Agent Response:\n",
      "The analysis of the MPG data reveals the following key trends:\n",
      "\n",
      "1. **Positive Correlation**: There is a strong positive correlation between City and Highway MPG, indicating that vehicles efficient in city driving are generally efficient on highways as well.\n",
      "\n",
      "2. **Car Type Distribution**:\n",
      "   - **Sedans** show a wide range of MPG values, indicating variability in fuel efficiency.\n",
      "   - **SUVs** tend to have lower MPG, clustering in the lower to mid-range.\n",
      "   - **Sports Cars** display a wide range, similar to sedans.\n",
      "   - **Wagons** and **Minivans** mainly cluster in the mid-range of MPG.\n",
      "\n",
      "3. **High Efficiency Outliers**: Some highly efficient vehicles are outliers, particularly among sedans.\n",
      "\n",
      "4. **Trend Line**: Confirms the positive correlation, with a majority of data points aligning predictably around it.\n",
      "\n",
      "5. **Efficiency Range**: City MPG ranges from ~10-60, and Highway MPG from ~10-70.\n",
      "\n",
      "Overall, sedans and sports cars have the most variability in fuel efficiency, while SUVs generally have lower MPG values.\n"
     ]
    }
   ],
   "source": [
    "# Define the question and data input\n",
    "question = \"What are the key trends regarding mpg for sales data set MPG range 0-100?\"\n",
    "data_input = \"https://raw.githubusercontent.com/uwdata/draco/master/data/cars.csv\" #this can also be a local file\n",
    "\n",
    "# Define the model deployment (ensure this matches your Azure OpenAI deployment)\n",
    "model_deployment = \"gpt-4o\"\n",
    "output_folder = \"output\"\n",
    "\n",
    "# Run the AI agent\n",
    "response = await analysis_agent(question, data_input,output_folder, model_deployment)\n",
    "\n",
    "# Display the response\n",
    "print(\"AI Agent Response:\")\n",
    "print(response['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee770d1",
   "metadata": {},
   "source": [
    "> **Note**: Ensure that the `data_input` URL is accessible and contains the data you intend to analyze. Replace it with your data source as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf4d2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analysis of the MPG data reveals the following key trends:\n",
      "\n",
      "1. **Positive Correlation**: There is a strong positive correlation between City and Highway MPG, indicating that vehicles efficient in city driving are generally efficient on highways as well.\n",
      "\n",
      "2. **Car Type Distribution**:\n",
      "   - **Sedans** show a wide range of MPG values, indicating variability in fuel efficiency.\n",
      "   - **SUVs** tend to have lower MPG, clustering in the lower to mid-range.\n",
      "   - **Sports Cars** display a wide range, similar to sedans.\n",
      "   - **Wagons** and **Minivans** mainly cluster in the mid-range of MPG.\n",
      "\n",
      "3. **High Efficiency Outliers**: Some highly efficient vehicles are outliers, particularly among sedans.\n",
      "\n",
      "4. **Trend Line**: Confirms the positive correlation, with a majority of data points aligning predictably around it.\n",
      "\n",
      "5. **Efficiency Range**: City MPG ranges from ~10-60, and Highway MPG from ~10-70.\n",
      "\n",
      "Overall, sedans and sports cars have the most variability in fuel efficiency, while SUVs generally have lower MPG values.\n"
     ]
    }
   ],
   "source": [
    "print(response['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **7. Conclusion**\n",
    "\n",
    "In this notebook, we've successfully transformed a script into an interactive Jupyter Notebook that sets up an AI agent using LIDA for data analysis. The agent can generate summaries, visualize data, and analyze generated charts, providing comprehensive insights based on user queries.\n",
    "\n",
    "**Next Steps**:\n",
    "\n",
    "- **Enhance Functionality**: Integrate additional tools or functionalities as needed.\n",
    "- **Error Handling**: Implement more robust error handling for production environments.\n",
    "- **User Interface**: Develop a user-friendly interface to interact with the AI agent seamlessly.\n",
    "- **Deployment**: Deploy the AI agent to a cloud platform for wider accessibility.\n",
    "\n",
    "Feel free to experiment with different data sources and questions to fully leverage the capabilities of your AI agent!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
